{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1KdbzzcXVHLNH9HRhwfFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vardhan-R/LLMs-Impersonate-Chat-Users/blob/main/LLM_WA_chats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Impersonates WhatsApp Users"
      ],
      "metadata": {
        "id": "AYFOi91BKDat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.ai.generativelanguage_v1beta.types import content\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import base64\n",
        "import datetime\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "ElX_Bw2OQD_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse the arguments\n",
        "\n",
        "model = \"gemini-1.5-flash\"  # @param {isTemplate: true}\n",
        "contents_b64 = b'W3sicGFydHMiOiBbeyJ0ZXh0IjogIkhlbGxvIn1dfV0='\n",
        "generation_config_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "# print(json.dumps(contents, indent=4))"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "KYZVwntXQAx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GEMINI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "ZgMCFjhEQiLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Message:\n",
        "\tdef __init__(self, text: str, sender: str, dt: datetime.datetime) -> None:\n",
        "\t\tself.text = text\n",
        "\t\tself.sender = sender\n",
        "\t\tself.datetime = dt  # IST\n",
        "\t\tself.uts = (dt - datetime.timedelta(hours=5, minutes=30)).timestamp()\n",
        "\n",
        "def getGeminiHistory(messages: list[Message]) -> list[dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Convert messages to Gemini history format.\n",
        "\n",
        "    Parameters:\n",
        "        messages (list[Message]): List of Message objects.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: List of messages in Gemini history format.\n",
        "    \"\"\"\n",
        "\n",
        "    gemini_history = []\n",
        "\n",
        "    for msg in messages:\n",
        "        role = \"user\" if msg.sender == \"Vardhan\" else \"model\"\n",
        "        gemini_history.append({\n",
        "            \"role\": role,\n",
        "            \"parts\": [\n",
        "                {\"text\": msg.text}\n",
        "            ]\n",
        "        })\n",
        "\n",
        "    return gemini_history\n",
        "\n",
        "def getMessages(other_person: str) -> list[Message]:\n",
        "\tmsg_pattern = r\"\\[(\\d{2})/(\\d{2})/(\\d{2}), (\\d{2}):(\\d{2}):(\\d{2})\\] ([^:]+): (.+)\"\n",
        "\tall_msgs = []\n",
        "\n",
        "\twith open(f\"./chats/{other_person}_chat.txt\", 'r', encoding=\"utf-8\") as fp:\n",
        "\t\traw_lines = fp.readlines()[1:]  # skip the encryption line\n",
        "\n",
        "\tfor line in raw_lines:\n",
        "\t\tm = re.match(msg_pattern, line)\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tdd = int(m.group(1))  # DD\n",
        "\t\t\tmo = int(m.group(2))  # MM\n",
        "\t\t\tyyyy = 2000 + int(m.group(3))  # YYYY\n",
        "\t\t\thh = int(m.group(4))  # hh\n",
        "\t\t\tmi = int(m.group(5))  # mm\n",
        "\t\t\tss = int(m.group(6))  # ss\n",
        "\t\t\tsender = m.group(7)  # sender\n",
        "\t\t\ttext = m.group(8)  # text\n",
        "\n",
        "\t\t\tdt = datetime.datetime(yyyy, mo, dd, hh, mi, ss)  # IST\n",
        "\t\t\tall_msgs.append(Message(text, sender, dt))\n",
        "\t\texcept:\n",
        "\t\t\tif chr(8206) not in line:  # continued text message\n",
        "\t\t\t\tall_msgs[-1].text += line\n",
        "\n",
        "\treturn all_msgs"
      ],
      "metadata": {
        "id": "hKWYb2ddZVkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 40,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.0-flash-exp\",\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings\n",
        ")"
      ],
      "metadata": {
        "id": "0PzxiPI-Q2Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# context = [\n",
        "#     {\n",
        "#         \"role\" : \"user\",\n",
        "#         \"parts\" : [\n",
        "#             {\n",
        "#                 \"text\" : \"You are a very hot and sassy girl. You know me for a few years, and also know that I have a crush on you.\"\n",
        "#             }\n",
        "#         ],\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "other_person = \"Aarushi\"\n",
        "context = getGeminiHistory(getMessages(other_person))\n",
        "print(len(context))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH1gxh2zar_G",
        "outputId": "4ae9fe93-a982-4792-f2f9-94c5f1fe6165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_session = model.start_chat(\n",
        "    history=context\n",
        ")"
      ],
      "metadata": {
        "id": "gbwyQLNCatJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while msg := input(\"You: \"):\n",
        "    response = chat_session.send_message(msg)\n",
        "    print(f\"{other_person}: \", end=\"\")\n",
        "    display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "0SrLcBfGgmTt",
        "outputId": "b456ec5c-9727-4d9c-a13f-2a363b6187a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: hi\n",
            "Aarushi: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hie\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: \n"
          ]
        }
      ]
    }
  ]
}